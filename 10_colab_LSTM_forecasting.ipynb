{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting: LSTM\n",
    "\n",
    "Open in [Colab](https://colab.google/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'colab' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "start_date = '2023-07-12'\n",
    "end_date = '2025-06-11'\n",
    "\n",
    "ticker = 'AAPL'\n",
    "data = yf.download(ticker, start=start_date, end=end_date, interval='1h')\n",
    "data.columns = data.columns.droplevel(1)\n",
    "data.columns.name = None\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Observations\n",
    "1. The dataset contains 3351 observations.\n",
    "2.  The attributes are all numeric except for a date column that is used as the index.\n",
    "3.  There are no missing values in the dataset.\n",
    "4.  The variable Close can be used as a target for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If we had categorical columns, we would need to identify them and encode them or extract a feature from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume-Price Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a copy with resample data to a day\n",
    "daily_data = data.resample('1D').agg({\n",
    "    'Open': 'first',\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Close': 'last',\n",
    "    'Volume': 'sum'\n",
    "}).dropna()\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, \n",
    "               vertical_spacing=0.03, subplot_titles=('Apple', 'Volume'), \n",
    "               row_width=[0.2, 0.7])\n",
    "\n",
    "fig.add_trace(go.Candlestick(\n",
    "    x=daily_data.index, \n",
    "    open=daily_data[\"Open\"], high=daily_data[\"High\"],\n",
    "    low=daily_data[\"Low\"], close=daily_data[\"Close\"], \n",
    "    name=\"Apple\"), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=daily_data.index, \n",
    "    y=daily_data['Volume'], \n",
    "    showlegend=False), row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis_title='Apple',\n",
    "    shapes=[dict(\n",
    "        x0=start_date, x1=end_date, y0=0, y1=1, xref='x', yref='paper',\n",
    "        line_width=2\n",
    "    )],\n",
    "    xaxis_rangeslider_visible=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features early on\n",
    "\n",
    "We're going to create three extra features with the moving average at different resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"5d_sma\"] = data[\"Close\"].rolling(window=5).mean()\n",
    "data[\"9d_sma\"] = data[\"Close\"].rolling(window=9).mean()\n",
    "data[\"17d_sma\"] = data[\"Close\"].rolling(window=17).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For filling the Nan values in SMAs columns, we're just using the exact close value this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['5d_sma'] = data['5d_sma'].fillna(data['Close'])\n",
    "data['9d_sma'] = data['9d_sma'].fillna(data['Close'])\n",
    "data['17d_sma'] = data['17d_sma'].fillna(data['Close'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Closing Price vs Moving Avergaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create plot with daily daya to gain clarity\n",
    "daily_data['5d_sma'] = daily_data['Close'].rolling(window=5).mean().fillna(data['Close'])\n",
    "daily_data['9d_sma'] = daily_data['Close'].rolling(window=9).mean().fillna(data['Close'])\n",
    "daily_data['17d_sma'] = daily_data['Close'].rolling(window=17).mean().fillna(data['Close'])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Close line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['Close'],\n",
    "    mode='lines',\n",
    "    name='Close',\n",
    "    line=dict(width=2)\n",
    "))\n",
    "\n",
    "# SMA 5 days\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['5d_sma'],\n",
    "    mode='lines',\n",
    "    name='5d SMA',\n",
    "    line=dict(dash='dot')\n",
    "))\n",
    "\n",
    "# SMA 9 days\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['9d_sma'],\n",
    "    mode='lines',\n",
    "    name='9d SMA',\n",
    "    line=dict(dash='dash')\n",
    "))\n",
    "\n",
    "# SMA 17 days\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['17d_sma'],\n",
    "    mode='lines',\n",
    "    name='17d SMA',\n",
    "    line=dict(dash='dashdot')\n",
    "))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    title='Apple Close Price with Daily SMAs',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price',\n",
    "    legend=dict(x=0, y=1.1, orientation='h'),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bollinger Bands\n",
    "\n",
    "**Bollinger Bands** are a popular technical analysis tool developed by John Bollinger. They consist of three lines: a simple moving average (SMA) in the middle, and two bands (upper and lower) plotted at a specified number of standard deviations above and below the SMA. \n",
    "\n",
    "These bands expand and contract based on market volatility. Traders use Bollinger Bands to identify overbought or oversold conditions, potential breakout opportunities, and to assess price volatility. When the price moves close to the upper band, the asset may be considered overbought; when it approaches the lower band, it may be considered oversold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Bollinger Bands Parameters\n",
    "window = 20  \n",
    "num_std = 2  \n",
    "\n",
    "# Central band (SMA)\n",
    "data['bb_mid'] = data['Close'].rolling(window=window).mean()\n",
    "\n",
    "# Rolling standard deviation\n",
    "rolling_std = data['Close'].rolling(window=window).std()\n",
    "\n",
    "# Upper band\n",
    "data['bb_upper'] = data['bb_mid'] + num_std * rolling_std\n",
    "\n",
    "# Lower band\n",
    "data['bb_lower'] = data['bb_mid'] - num_std * rolling_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "daily_data = data.resample('1D').mean().bfill()\n",
    "\n",
    "# Gráfico de velas\n",
    "fig.add_trace(go.Candlestick(\n",
    "    x=daily_data.index,\n",
    "    open=daily_data['Open'],\n",
    "    high=daily_data['High'],\n",
    "    low=daily_data['Low'],\n",
    "    close=daily_data['Close'],\n",
    "    name='Price'\n",
    "))\n",
    "\n",
    "# Bandas de Bollinger (solo líneas)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['bb_upper'],\n",
    "    name='Upper Band', line=dict(color='rgba(173,216,230,0.75)', dash='dot')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['bb_mid'],\n",
    "    name='Middle Band', line=dict(color='blue')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_data.index, y=daily_data['bb_lower'],\n",
    "    name='Lower Band', line=dict(color='rgba(173,216,230,0.75)', dash='dot')\n",
    "))\n",
    "\n",
    "# Configuración final\n",
    "fig.update_layout(\n",
    "    title='Bollinger Bands on Daily Price',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Price',\n",
    "    template='plotly_white',\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    xaxis_rangeslider_visible=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "### Preparing Dataloader and Model classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class defines the architecture of a custom LSTM-based neural network used for time series prediction, specifically for forecasting stock closing prices.\n",
    "\n",
    "**What happens in the __init__ method?**\n",
    "This method sets up the layers of the model.\n",
    "- input_size: How many features are given as input at each time step (e.g., Open, Volume, etc.).\n",
    "- hidden_size: The number of “memory units” in each LSTM layer — more units can help the model learn more complex patterns.\n",
    "- layers: How many LSTM layers are stacked on top of each other.\n",
    "- output_size: The size of the model’s final output — for predicting one value, this is usually 1.\n",
    "\n",
    "\n",
    "**Layers defined**:\n",
    "- ```self.lstm```: A multi-layer LSTM with the given parameters. It processes sequential input data.\n",
    "- ```sself.fc1```: A fully connected (linear) layer that maps the output from the last time step of the LSTM to the final prediction.\n",
    "\n",
    "> The architecture could be extended into a deeper feedforward structure if needed.\n",
    "\n",
    "**What happens in the forward method?**\n",
    "The forward method defines how the data flows through the model.\n",
    "First the **hidden state (h0)** and **cell state (c0)** are intialized. They’re like the memory of the LSTM. Then the input data is passed through the LSTM, then it returns:\n",
    "\n",
    "- out: all LSTM outputs for each time step\n",
    "- h_out, c_out: the final hidden and cell states (not used here)\n",
    "\n",
    "The last step goes through a fully connected layer to produce the predicted value.\n",
    "The squeeze(1) removes any extra dimensions so the output is clean and ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmNet(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,layers,output_size):\n",
    "        super(LstmNet,self).__init__()\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=layers, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
    "        # self.fc2 = nn.Linear(10,output_size)\n",
    "    def forward(self,x):\n",
    "        # print(x.shape)\n",
    "        h0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_size)).to(device)\n",
    "\n",
    "        c0 = Variable(torch.zeros(self.layers, x.size(0), self.hidden_size)).to(device)\n",
    "        out, (h_out, c_out) = self.lstm(x,(h0,c0))\n",
    "        # print(out.shape,h_out.shape,c_out.shape)\n",
    "        out = self.fc1(out[:,-1,:])\n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we can use GPU accelaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for LSTM\n",
    "\n",
    "Before training an LSTM model, we need to **transform the data into sequences** that the model can learn from. These helper functions and classes prepare the dataset accordingly.\n",
    "\n",
    "**prepare_dataset(data, length)**:\n",
    "\n",
    "This function creates input sequences and targets from a time series.\n",
    "- It slides a window of size length over the data. For each window:\n",
    "    - The input (x) is the sequence of values inside the window.\n",
    "    - The target (y) is the value that comes right after the window.\n",
    "\n",
    "**train_test_split(X, Y, percent)**:\n",
    "splits the dataset into training and testing sets, based on a percentage. Importantly, this split keeps the time order of the data \n",
    "\n",
    "\n",
    "**DataPrep Class**:\n",
    "this is a custom PyTorch Dataset class that wraps the inputs and targets so they can be loaded by a DataLoader. This class makes it easy to feed data into the LSTM in batches while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data,length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data)-length-1):\n",
    "        x.append(data[i:i+length])\n",
    "        y.append(data[i+length])\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "def train_test_split(X,Y,percent):\n",
    "    per = percent/100\n",
    "    sz = len(X)\n",
    "    xtrain = torch.Tensor(X[:int(sz*per)])\n",
    "    ytrain = torch.Tensor(Y[:int(sz*per)])\n",
    "    xtest = torch.Tensor(X[int(sz*per):])\n",
    "    ytest = torch.Tensor(Y[int(sz*per):])\n",
    "    return xtrain,ytrain,xtest,ytest\n",
    "\n",
    "class DataPrep(Dataset):\n",
    "  def __init__(self, inputs, targets):\n",
    "      self.inputs = inputs\n",
    "      self.targets = targets\n",
    "  def __len__(self):\n",
    "      return len(self.inputs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      X = self.inputs[index]\n",
    "      Y = self.targets[index]\n",
    "      return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding data into a neural network, especially an LSTM, it’s important to **normalize the values**. This is due to the fact that neural networks are sensitive to the scale of input data. If the values are too large (e.g., stock prices in the hundreds) or vary a lot, the training process can become unstable or slow.\n",
    "\n",
    "By scaling the Close prices, the model can focus on learning patterns rather than dealing with raw magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "values = scaler.fit_transform(data['Close'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 40\n",
    "data_inp, data_tar = prepare_dataset(values, seq_len)\n",
    "xtrain, ytrain, xtest, ytest = train_test_split(data_inp, data_tar, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing and splitting the data, we wrap it in PyTorch DataLoaders to handle **batching** and **shuffling** during training. shuffle=True ensures the training data is mixed before each epoch — this helps the model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DataPrep(xtrain,ytrain)\n",
    "testdata = DataPrep(xtest,ytest)\n",
    "batch_size = 32\n",
    "trainset = DataLoader(traindata,batch_size = batch_size,shuffle = True)\n",
    "testset = DataLoader(testdata,batch_size = batch_size,shuffle = True)\n",
    "for xbatch,ybatch in trainset:\n",
    "    print(xbatch.shape,ybatch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "input_sz = 1\n",
    "hidden_sz = 200\n",
    "output_sz = 1\n",
    "layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This blocks of code train the LSTM model using Mean Squared Error as the loss function and Stochastic Gradient Descent (SGD) as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmNet(input_sz,hidden_sz,layers,output_sz).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside each epoch:\n",
    "\n",
    "**1.\tTraining Phase.\n",
    "For every batch of data:**\n",
    "- Move the batch to the selected device (CPU/GPU).\n",
    "- Pass the inputs through the model to get predictions.\n",
    "- Compute the loss between predictions and actual values.\n",
    "- Call .backward() to calculate gradients.\n",
    "- Call .step() to update model weights.\n",
    "- Accumulate the batch losses.\n",
    "  \n",
    "**2. Testing Phase (Evaluation):**\n",
    "- No gradients are needed during evaluation, so torch.no_grad() is used.\n",
    "- The model is tested on unseen data (the test set).\n",
    "- Loss is computed but the model weights are not updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "\n",
    "for epoch in trange(epochs, desc=\"Training Epochs\"):\n",
    "    batch_loss = 0\n",
    "    for xbatch,ybatch in trainset:\n",
    "        xbatch,ybatch = xbatch.to(device),ybatch.to(device),\n",
    "        out = model(xbatch)\n",
    "        loss = criterion(out, ybatch.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    train_loss = batch_loss/len(trainset)\n",
    "    batch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xbatch,ybatch in testset:\n",
    "            xbatch,ybatch = xbatch.to(device),ybatch.to(device)\n",
    "            out = model(xbatch)\n",
    "            loss = criterion(out, ybatch.squeeze(1))\n",
    "            batch_loss += loss.item()\n",
    "    test_loss = batch_loss/len(testset)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    if(epoch%10==9):\n",
    "        print(\"\\nEpoch: \", epoch+1, \"|\", \"Train Loss : \", \"{:.6f}\".format(train_loss), \"|\", \"Test Loss : \", \"{:.6f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions with the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the LSTM model, we use it to make predictions on both the **training** and **testing** datasets to evaluate how well it has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model(xtrain.to(device)).cpu().data.numpy()\n",
    "train_actual = ytrain.data.numpy()\n",
    "test_pred = model(xtest.to(device)).cpu().data.numpy()\n",
    "test_actual = ytest.data.numpy()\n",
    "\n",
    "pred = np.concatenate((train_pred,test_pred))\n",
    "actual = np.concatenate((train_actual,test_actual)).squeeze()\n",
    "\n",
    "print(pred.shape)\n",
    "print(actual.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = [(i+1) for i in range(len(pred))],y = pred, name='Predicted Data')\n",
    "trace2 = go.Scatter(x = [(i+1) for i in range(len(actual))],y = actual, name='Actual data')\n",
    "\n",
    "datas = [trace1,trace2]\n",
    "\n",
    "layout = go.Layout(title='Prediction for 80:20 split Simple LSTM')\n",
    "fig = go.Figure(data=datas, layout=layout)\n",
    "fig.add_vline(x=len(train_pred), line_width=1, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
